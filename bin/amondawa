#!/usr/bin/env ipython --autocall=2 -i
#
# vim: filetype=python
#
# Copyright (c) 2013 Daniel Gardner
# All rights reserved.
#
# Permission is hereby granted, free of charge, to any person obtaining a
# copy of this software and associated documentation files (the
# "Software"), to deal in the Software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish, dis-
# tribute, sublicense, and/or sell copies of the Software, and to permit
# persons to whom the Software is furnished to do so, subject to the fol-
# lowing conditions:
#
# The above copyright notice and this permission notice shall be included
# in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABIL-
# ITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT
# SHALL THE AUTHOR BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
# WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
# IN THE SOFTWARE.

from tests.http_writer import *
from tests.stats import Intervals
from tests.query import QueryRunner

import time, random, simplejson

INTERVALS = Intervals()

REGION        = 'us-west-2'

HOST          = 'amondawa.elasticbeanstalk.com'
PORT          = 80

RATE          = 100.     # overall rate (split across NTHREADS)
NTHREADS      = 10       # how many threads to use
DURATION      = 10       # duration in minutes
BATCH_SIZE    = 2        # datapoints per request

WRITERS       = []       # writers
QUERY_RUNNER  = None     # query thread/runner
LAST_QUERY    = None     # last query performed
LAST_RESPONSE = None     # last response received

SAVED_QUERIES = {}       # saved queries

def settings():
  """Show current settings.
  """
  global HOST, PORT, DURATION, RATE, NTHREADS, REGION
  print """
region:     %s
host:       %s
port:       %s
duration:   %s
rate:       %s
threads:    %s
batch_size: %s
""" % (REGION, HOST, PORT, DURATION, RATE, NTHREADS, BATCH_SIZE)

def commands():
  print """
amondawa commands
-----------------
host         : set host
port         : set port
host_port    : set host and port

batch_size   : set per/thread batch size
flush        : flush writers

start        : create threads and start sending 
pause        : pause writers
resume       : resume writers
stop         : terminate writers
reset        : reset writers, intervals

rate         : set aggregate rate
threads      : set threads

status       : show status
streams      : show current streams

random_query : construct a random query (dict) 
               based on current streams
query        : perform a query (specified as dict)
query_last   : repeat the previous query
named_query  : repeat a saved query
save_query   : save current query
list_queries : list query names
"""

def host(host, supress=False):
  global HOST
  HOST = host
  if not supress:
    settings()

def port(port, supress=False):
  global PORT
  PORT = port
  if not supress:
    settings()

def host_port(host_, port_):
  host(host_, True)
  port(port_, True)
  settings()

def rate(rate):
  global RATE
  RATE = rate
  settings()

def threads(count):
  global NTHREADS
  NTHREADS = count
  settings()

def batch_size(batch_size):
  global BATCH_SIZE
  BATCH_SIZE = batch_size
  settings()

def reset():
  global INTERVALS, WRITERS, QUERY_RUNNER, LAST_QUERY, \
       LAST_RESPONSE
  stop()
  INTERVALS = Intervals()
  WRITERS = []
  QUERY_RUNNER = None
  LAST_QUERY = None
  LAST_RESPONSE = None

def start():
  global WRITERS, NTHREADS, RATE, INTERVALS
  stop()
  WRITERS = [RandomHTTPWriter(HOST, PORT, rate=RATE/NTHREADS, 
     duration=DURATION, batch_size=BATCH_SIZE) for i in range(NTHREADS)]
  for writer in WRITERS:
    writer.start()
  if WRITERS: INTERVALS.start_interval()

def flush():
  global WRITERS
  for writer in WRITERS:
    print writer.flush()

def resume():
  global WRITERS, INTERVALS
  for writer in WRITERS:
    writer.unpause()
  if WRITERS: INTERVALS.start_interval()

def pause():
  global WRITERS, INTERVALS
  totals = []
  for writer in WRITERS:
    writer.pause()
    totals.append(writer.reset_stats())
  if WRITERS and INTERVALS.running(): 
    INTERVALS.end_interval(totals)

def stop():
  global WRITERS, INTERVALS
  totals = []
  for writer in WRITERS:
    writer.stop()
    totals.append(writer.reset_stats())
  if WRITERS and INTERVALS.running(): 
    INTERVALS.end_interval(totals)
  WRITERS = []

def status():
  global WRITERS, INTERVALS
  if not WRITERS:
    status = 'STOPPED'
  elif INTERVALS.running():
    status = 'RUNNING'
  else:
    status = 'PAUSED'
  print 'status:', status
  print
  sub_totals = [writer.totals() for writer in WRITERS]
  for sub in sub_totals:
    print sub
  INTERVALS.print_history(sub_totals)

def streams():
  global WRITERS
  for writer in WRITERS:
    print writer

def save_query(name):
  global SAVED_QUERIES, LAST_QUERY
  SAVED_QUERIES[name] = LAST_QUERY

def query_last():
  global LAST_QUERY
  return query(LAST_QUERY)

def named_query(name):
  global SAVED_QUERIES
  return query(SAVED_QUERIES[name])

def list_queries():
  global SAVED_QUERIES
  return SAVED_QUERIES.keys()

def query(query=None):
  global QUERY_RUNNER, HOST, PORT, LAST_QUERY, LAST_RESPONSE, WRITERS
  if not WRITERS: 
    return

  if not QUERY_RUNNER:
    QUERY_RUNNER = QueryRunner(HOST, PORT)

  if not query:
    query = random_query()

  LAST_QUERY = query
  response = QUERY_RUNNER.perform_query(query)
  LAST_RESPONSE = response.status, response.reason, \
        simplejson.loads(response.read())

  return LAST_QUERY, LAST_RESPONSE

def random_query():
  if not WRITERS: return
  start, end = INTERVALS.choose_random_interval()

  metrics = []
  query = {
      'start_absolute': start,
      'end_absolute': end,
      'metrics': metrics
      }
 
  # pick some streams to match
  streams = random.sample(WRITERS, random.randint(1,3))

  # for each stream pick some tags that will match
  mtags = {}
  for stream in streams:
    metric, tags = stream.metric, stream.tags
    mkeys = random.sample(tags.keys(), random.randint(1,3))
    mtags = dict(zip(mkeys, [tags[k] for k in mkeys]))
    metrics.append({
      'tags': mtags,
      'name': metric
      })
  return query

commands()
